{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b459cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd23603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.48MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 113kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 909kB/s] \n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.13MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=0.5, std=0.5)  # (x - 0.5) / 0.5 = 2x - 1\n",
    "])\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    root='./mnist_data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST(\n",
    "    root='./mnist_data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(mnist_train)}\")\n",
    "print(f\"Test samples: {len(mnist_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d30632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 1875\n",
      "Number of test batches: 313\n"
     ]
    }
   ],
   "source": [
    "# Set up DataLoaders\n",
    "batch_size = 32  # Adjust based on your CPU capacity\n",
    "train_loader = DataLoader(\n",
    "    mnist_train, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=2  # Adjust based on your CPU\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    mnist_test, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48474fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generator network for MNIST GAN\n",
    "    Maps noise vector z (dim 100) to fake images (28x28 = 784)\n",
    "    Architecture: 100 -> 256 -> 512 -> 784\n",
    "    \"\"\"\n",
    "    def __init__(self, noise_dim=100, hidden_dim1=256, hidden_dim2=512, output_dim=784):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.noise_dim = noise_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(noise_dim, hidden_dim1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)  # Optional batch normalization\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim2)\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights following DCGAN paper recommendations\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass through generator\n",
    "        Args:\n",
    "            z: Noise vector of shape [batch_size, noise_dim]\n",
    "        Returns:\n",
    "            Generated images of shape [batch_size, 1, 28, 28]\n",
    "        \"\"\"\n",
    "        # First hidden layer\n",
    "        x = self.fc1(z)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Second hidden layer\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.fc3(x)\n",
    "        x = torch.tanh(x)  # Output in [-1, 1] to match normalized MNIST\n",
    "        \n",
    "        # Reshape to image format [batch_size, 1, 28, 28]\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator network for MNIST GAN\n",
    "    Maps flattened images (784) to probability of being real\n",
    "    Architecture: 784 -> 256 -> 256 -> 1\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=784, hidden_dim1=256, hidden_dim2=256, dropout_prob=0.3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_dim2, 1)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights following DCGAN paper recommendations\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through discriminator\n",
    "        Args:\n",
    "            x: Images of shape [batch_size, 1, 28, 28] or [batch_size, 784]\n",
    "        Returns:\n",
    "            Probability of being real [batch_size, 1]\n",
    "        \"\"\"\n",
    "        # Flatten if needed\n",
    "        if len(x.shape) == 4:  # [batch_size, 1, 28, 28]\n",
    "            x = x.view(x.size(0), -1)  # [batch_size, 784]\n",
    "        \n",
    "        # First hidden layer\n",
    "        x = self.fc1(x)\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Second hidden layer\n",
    "        x = self.fc2(x)\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)  # Output probability [0, 1]\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c080ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANTrainer:\n",
    "    def __init__(self, generator, discriminator, device, lr=2e-4, beta1=0.5, beta2=0.999, \n",
    "                 label_smoothing=True, smooth_real_labels=0.9):\n",
    "        \"\"\"\n",
    "        GAN Trainer with optimized hyperparameters\n",
    "        \n",
    "        Args:\n",
    "            generator: Generator model\n",
    "            discriminator: Discriminator model  \n",
    "            device: Training device (cuda/cpu)\n",
    "            lr: Learning rate for both optimizers\n",
    "            beta1: Beta1 parameter for Adam (reduced for GAN stability)\n",
    "            beta2: Beta2 parameter for Adam\n",
    "            label_smoothing: Whether to apply one-sided label smoothing\n",
    "            smooth_real_labels: Value for smoothed real labels (default 0.9)\n",
    "        \"\"\"\n",
    "        self.generator = generator.to(device)\n",
    "        self.discriminator = discriminator.to(device)\n",
    "        self.device = device\n",
    "        \n",
    "        # Optimizers with GAN-specific hyperparameters\n",
    "        self.optimizer_G = optim.Adam(\n",
    "            self.generator.parameters(), \n",
    "            lr=lr, \n",
    "            betas=(beta1, beta2)\n",
    "        )\n",
    "        \n",
    "        self.optimizer_D = optim.Adam(\n",
    "            self.discriminator.parameters(), \n",
    "            lr=lr, \n",
    "            betas=(beta1, beta2)\n",
    "        )\n",
    "        \n",
    "        # Loss function\n",
    "        self.criterion = nn.BCELoss()\n",
    "        \n",
    "        # Label smoothing settings\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.smooth_real_labels = smooth_real_labels\n",
    "        \n",
    "        # Training statistics\n",
    "        self.losses_G = []\n",
    "        self.losses_D = []\n",
    "        self.losses_D_real = []\n",
    "        self.losses_D_fake = []\n",
    "        \n",
    "        print(f\"GAN Trainer initialized:\")\n",
    "        print(f\"  Learning rate: {lr}\")\n",
    "        print(f\"  Adam betas: ({beta1}, {beta2})\")\n",
    "        print(f\"  Label smoothing: {label_smoothing}\")\n",
    "        if label_smoothing:\n",
    "            print(f\"  Smooth real labels: {smooth_real_labels}\")\n",
    "        print(f\"  Device: {device}\")\n",
    "    \n",
    "    def get_labels(self, batch_size, real=True):\n",
    "        \"\"\"\n",
    "        Generate labels for real/fake data with optional smoothing\n",
    "        \n",
    "        Args:\n",
    "            batch_size: Size of the batch\n",
    "            real: True for real data labels, False for fake data labels\n",
    "            \n",
    "        Returns:\n",
    "            Labels tensor of appropriate shape\n",
    "        \"\"\"\n",
    "        if real:\n",
    "            if self.label_smoothing:\n",
    "                # One-sided label smoothing: real labels = 0.9 instead of 1.0\n",
    "                labels = torch.full((batch_size, 1), self.smooth_real_labels, \n",
    "                                  dtype=torch.float32, device=self.device)\n",
    "            else:\n",
    "                labels = torch.ones(batch_size, 1, dtype=torch.float32, device=self.device)\n",
    "        else:\n",
    "            # Always use 0.0 for fake labels (no smoothing)\n",
    "            labels = torch.zeros(batch_size, 1, dtype=torch.float32, device=self.device)\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    def train_discriminator(self, real_images, noise):\n",
    "        \"\"\"\n",
    "        Train discriminator on both real and fake images\n",
    "        \n",
    "        Args:\n",
    "            real_images: Batch of real images\n",
    "            noise: Random noise for generating fake images\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with discriminator losses\n",
    "        \"\"\"\n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        # Clear discriminator gradients\n",
    "        self.optimizer_D.zero_grad()\n",
    "        \n",
    "        # === Train on real images ===\n",
    "        real_labels = self.get_labels(batch_size, real=True)\n",
    "        real_predictions = self.discriminator(real_images)\n",
    "        loss_D_real = self.criterion(real_predictions, real_labels)\n",
    "        \n",
    "        # === Train on fake images ===\n",
    "        fake_images = self.generator(noise)\n",
    "        fake_labels = self.get_labels(batch_size, real=False)\n",
    "        fake_predictions = self.discriminator(fake_images.detach())  # Detach to avoid training G\n",
    "        loss_D_fake = self.criterion(fake_predictions, fake_labels)\n",
    "        \n",
    "        # Total discriminator loss\n",
    "        loss_D = loss_D_real + loss_D_fake\n",
    "        loss_D.backward()\n",
    "        self.optimizer_D.step()\n",
    "        \n",
    "        return {\n",
    "            'loss_D_total': loss_D.item(),\n",
    "            'loss_D_real': loss_D_real.item(),\n",
    "            'loss_D_fake': loss_D_fake.item(),\n",
    "            'real_predictions': real_predictions.mean().item(),\n",
    "            'fake_predictions': fake_predictions.mean().item()\n",
    "        }\n",
    "    \n",
    "    def train_generator(self, noise):\n",
    "        \"\"\"\n",
    "        Train generator using non-saturating loss\n",
    "        \n",
    "        Args:\n",
    "            noise: Random noise for generating fake images\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with generator losses\n",
    "        \"\"\"\n",
    "        batch_size = noise.size(0)\n",
    "        \n",
    "        # Clear generator gradients\n",
    "        self.optimizer_G.zero_grad()\n",
    "        \n",
    "        # Generate fake images\n",
    "        fake_images = self.generator(noise)\n",
    "        \n",
    "        # Non-saturating loss: use real labels (1) for fake images\n",
    "        # This maximizes log(D(G(z))) instead of minimizing log(1-D(G(z)))\n",
    "        real_labels = self.get_labels(batch_size, real=True)\n",
    "        fake_predictions = self.discriminator(fake_images)\n",
    "        loss_G = self.criterion(fake_predictions, real_labels)\n",
    "        \n",
    "        loss_G.backward()\n",
    "        self.optimizer_G.step()\n",
    "        \n",
    "        return {\n",
    "            'loss_G': loss_G.item(),\n",
    "            'fake_predictions_for_G': fake_predictions.mean().item()\n",
    "        }\n",
    "    \n",
    "    def train_epoch(self, dataloader, noise_dim=100):\n",
    "        \"\"\"\n",
    "        Train both networks for one epoch\n",
    "        \n",
    "        Args:\n",
    "            dataloader: DataLoader for training data\n",
    "            noise_dim: Dimension of noise vector\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with epoch statistics\n",
    "        \"\"\"\n",
    "        self.generator.train()\n",
    "        self.discriminator.train()\n",
    "        \n",
    "        epoch_losses_G = []\n",
    "        epoch_losses_D = []\n",
    "        epoch_losses_D_real = []\n",
    "        epoch_losses_D_fake = []\n",
    "        \n",
    "        progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "        \n",
    "        for batch_idx, (real_images, _) in enumerate(progress_bar):\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = real_images.to(self.device)\n",
    "            \n",
    "            # Generate random noise\n",
    "            noise = torch.randn(batch_size, noise_dim, device=self.device)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            d_stats = self.train_discriminator(real_images, noise)\n",
    "            \n",
    "            # Train Generator\n",
    "            g_stats = self.train_generator(noise)\n",
    "            \n",
    "            # Store losses\n",
    "            epoch_losses_G.append(g_stats['loss_G'])\n",
    "            epoch_losses_D.append(d_stats['loss_D_total'])\n",
    "            epoch_losses_D_real.append(d_stats['loss_D_real'])\n",
    "            epoch_losses_D_fake.append(d_stats['loss_D_fake'])\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'D_loss': f\"{d_stats['loss_D_total']:.4f}\",\n",
    "                'G_loss': f\"{g_stats['loss_G']:.4f}\",\n",
    "                'D(x)': f\"{d_stats['real_predictions']:.3f}\",\n",
    "                'D(G(z))': f\"{d_stats['fake_predictions']:.3f}\"\n",
    "            })\n",
    "        \n",
    "        # Calculate epoch averages\n",
    "        avg_loss_G = np.mean(epoch_losses_G)\n",
    "        avg_loss_D = np.mean(epoch_losses_D)\n",
    "        avg_loss_D_real = np.mean(epoch_losses_D_real)\n",
    "        avg_loss_D_fake = np.mean(epoch_losses_D_fake)\n",
    "        \n",
    "        # Store for plotting\n",
    "        self.losses_G.append(avg_loss_G)\n",
    "        self.losses_D.append(avg_loss_D)\n",
    "        self.losses_D_real.append(avg_loss_D_real)\n",
    "        self.losses_D_fake.append(avg_loss_D_fake)\n",
    "        \n",
    "        return {\n",
    "            'avg_loss_G': avg_loss_G,\n",
    "            'avg_loss_D': avg_loss_D,\n",
    "            'avg_loss_D_real': avg_loss_D_real,\n",
    "            'avg_loss_D_fake': avg_loss_D_fake\n",
    "        }\n",
    "    \n",
    "    def generate_samples(self, num_samples=64, noise_dim=100):\n",
    "        \"\"\"Generate samples for visualization\"\"\"\n",
    "        self.generator.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            noise = torch.randn(num_samples, noise_dim, device=self.device)\n",
    "            fake_images = self.generator(noise)\n",
    "        \n",
    "        return fake_images\n",
    "    \n",
    "    def plot_losses(self):\n",
    "        \"\"\"Plot training losses\"\"\"\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        epochs = range(1, len(self.losses_G) + 1)\n",
    "        \n",
    "        # Plot Generator and Discriminator losses\n",
    "        axes[0].plot(epochs, self.losses_G, label='Generator Loss', color='blue')\n",
    "        axes[0].plot(epochs, self.losses_D, label='Discriminator Loss', color='red')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].set_title('Generator vs Discriminator Loss')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot Discriminator breakdown\n",
    "        axes[1].plot(epochs, self.losses_D_real, label='D Loss (Real)', color='green')\n",
    "        axes[1].plot(epochs, self.losses_D_fake, label='D Loss (Fake)', color='orange')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Loss')\n",
    "        axes[1].set_title('Discriminator Loss Breakdown')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def visualize_samples(fake_images, epoch=None, num_samples=16):\n",
    "    \"\"\"Visualize generated samples\"\"\"\n",
    "    # Convert from [-1,1] to [0,1] for visualization\n",
    "    fake_images = (fake_images + 1) / 2\n",
    "    fake_images = torch.clamp(fake_images, 0, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        row, col = i // 4, i % 4\n",
    "        img = fake_images[i].cpu().squeeze()\n",
    "        axes[row, col].imshow(img, cmap='gray')\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    title = f'Generated Samples (Epoch {epoch})' if epoch else 'Generated Samples'\n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def full_training_loop(generator, discriminator, train_loader, epochs=50, noise_dim=100, \n",
    "                      lr=2e-4, label_smoothing=True, device=None):\n",
    "    \"\"\"\n",
    "    Complete training loop with visualization\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = GANTrainer(\n",
    "        generator, discriminator, device, \n",
    "        lr=lr, label_smoothing=label_smoothing\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nStarting GAN training for {epochs} epochs...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        \n",
    "        # Train for one epoch\n",
    "        epoch_stats = trainer.train_epoch(train_loader, noise_dim)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch {epoch} Summary:\")\n",
    "        print(f\"  Generator Loss: {epoch_stats['avg_loss_G']:.4f}\")\n",
    "        print(f\"  Discriminator Loss: {epoch_stats['avg_loss_D']:.4f}\")\n",
    "        print(f\"    - Real Loss: {epoch_stats['avg_loss_D_real']:.4f}\")\n",
    "        print(f\"    - Fake Loss: {epoch_stats['avg_loss_D_fake']:.4f}\")\n",
    "        \n",
    "        # Generate and show samples every 5 epochs\n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            fake_images = trainer.generate_samples(16, noise_dim)\n",
    "            visualize_samples(fake_images, epoch, num_samples=16)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "    print(f\"Average time per epoch: {training_time/epochs:.2f} seconds\")\n",
    "    \n",
    "    # Plot final losses\n",
    "    trainer.plot_losses()\n",
    "    \n",
    "    # Generate final samples\n",
    "    print(\"\\nFinal generated samples:\")\n",
    "    final_samples = trainer.generate_samples(16, noise_dim)\n",
    "    visualize_samples(final_samples, epoch=epochs, num_samples=16)\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize models (using previously defined architectures)\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "print(\"Testing training setup...\")\n",
    "\n",
    "# Test with dummy data\n",
    "batch_size = 32\n",
    "noise_dim = 100\n",
    "\n",
    "# Create trainer\n",
    "trainer = GANTrainer(generator, discriminator, device, label_smoothing=True)\n",
    "\n",
    "# Test one training step\n",
    "dummy_images = torch.randn(batch_size, 1, 28, 28).to(device)\n",
    "dummy_noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "\n",
    "print(\"\\nTesting discriminator training...\")\n",
    "d_stats = trainer.train_discriminator(dummy_images, dummy_noise)\n",
    "print(f\"D stats: {d_stats}\")\n",
    "\n",
    "print(\"\\nTesting generator training...\")\n",
    "g_stats = trainer.train_generator(dummy_noise)\n",
    "print(f\"G stats: {g_stats}\")\n",
    "\n",
    "print(\"\\nTesting sample generation...\")\n",
    "samples = trainer.generate_samples(16, noise_dim)\n",
    "print(f\"Generated samples shape: {samples.shape}\")\n",
    "print(f\"Samples range: [{samples.min():.3f}, {samples.max():.3f}]\")\n",
    "\n",
    "print(\"\\n✓ Training setup verified and ready!\")\n",
    "\n",
    "# Uncomment to run full training\n",
    "trainer = full_training_loop(generator, discriminator, train_loader, \n",
    "                            epochs=50, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atml_pa0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
